---
title: "Lab 10 - Grading the professor, Pt. 2"
author: "Ben Hardin"
date: "3/14/2023"
output: github_document
---

### Load packages and data

```{r load-packages, message=FALSE}
library(tidyverse) 
library(tidymodels)
library(openintro)
```

### Exercise 1

The linear model: score = 3.88 + .067(average beauty)

R^2 = 3.5%
Adjusted R^2 = 3.3%

```{r linear-beauty}
m_bty <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg, data = evals)

tidy(m_bty)

glance(m_bty)$r.squared

glance(m_bty)$adj.r.squared
```

### Exercise 2

The linear model: score = 3.75 + .07(beauty) + .17(gender)

R^2 = 5.9%
Adjusted R^2 = 5.5%

```{r beauty-gender}
m_bty_gen <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg + gender, data = evals)

tidy(m_bty_gen)

glance(m_bty_gen)$r.squared

glance(m_bty_gen)$adj.r.squared
```

### Exercise 3

Intercept: Female instructors who have a beauty rating of 0 are predicted, on average, to receive a course evaluation score of about 3.75

Slope of gender: Holding beauty constant, course evaluation scores are predicted, on average, to be .17 points higher for male instructors compared to female instructors.

### Exercise 4

The model including average beauty and gender explains about 5.9% of the variance in course evaluation scores.

### Exercise 5

Linear model for male instructors: score = 3.92 + .07(beauty)

### Exercise 6

For two professors who had the same beauty rating, this model predicts that male professors would have higher course evaluation scores.

### Exercise 7

This is a question about an interaction, but I only tested main effects in my previous model. So now, let's run a model including the interaction term to answer this question. I also made a centered version of the average beauty score, to make the slopes easier to interpret.

```{r interaction}
evals <- evals %>%
  mutate(bty_centered = (bty_avg - mean(bty_avg)))

m_bty_gen <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_centered * gender, data = evals)

tidy(m_bty_gen)

glance(m_bty_gen)$r.squared

glance(m_bty_gen)$adj.r.squared
```

The slope of the interaction is about .08, indicating that the slope for beauty predicting course evaluation scores differs between male versus female instructors. Specifically, the slope for beauty is predicted to be about .08 points greater for male instructors than for female instructors, meaning there is a stronger relationship between beauty and course evaluations for male instructors than for female instructors.


### Exercise 8

The adjusted R^2 when only beauty is included in the model is .033, while the adjusted R^2 when both beauty, gender, and the beauty x gender interaction are included in the model is .065. This indicates that the addition of gender to the model increases the percentage of variance explained by the model, and that gender carries some additional explanatory power above and beyond beauty for predicting course evaluation scores.

### Exercise 9

When beauty was entered as a standalone predictor, it had a slope of about .07. The slope was similar, but slightly larger, in the model including both main effects of beauty and of gender. In the model including the beauty x gender interaction, the slope decreased to about .03. Thus, adding the interaction to the model has changed the estimated effect of beauty on evaluation scores.

### Exercise 10

The linear model: score = 3.98 + .07(beauty) + -.16(tenure track) + -.13(tenured)

Intercept: Teaching faculty with a beauty score of 0 are predicted, on average, to have a course evaluation score of about 3.98.

Slope of beauty: Holding rank constant, course evaluation scores are predicted, on average, to be .07 points higher for each 1 point that a professor's beauty score is greater.

Slopes of rank: Holding beauty constant, course evaluation scores are predicted, on average, to be .16 points lower for tenure track faculty, and about .13 points lower for tenured faculty, compared to teaching faculty.

```{r rank}
m_bty_rank <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ bty_avg + rank, data = evals)

tidy(m_bty_rank)
```

### Exercise 11

Level

### Exercise 12

```{r weak}
m_level <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ cls_level, data = evals)

tidy(m_level)
```

### Exercise 13

Kick out did eval

### Exercise 14

```{r big-model}
m_full <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ rank + ethnicity + gender + language + age + cls_perc_eval + cls_students + cls_level + cls_profs + cls_credits + bty_avg, data = evals)

tidy(m_full)

glance(m_full)$r.squared

glance(m_full)$adj.r.squared
```

### Exercise 15

```{r final-model}
m_final <- linear_reg() %>%
  set_engine("lm") %>%
  fit(score ~ rank + ethnicity + gender + language + age + cls_perc_eval + cls_credits + bty_avg, data = evals)

tidy(m_final)

glance(m_final)$r.squared

glance(m_final)$adj.r.squared
```
